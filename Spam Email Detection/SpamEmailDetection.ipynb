{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "P4DdPMtLIzd8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'Spam Email Detection.xlsx'\n",
        "data = pd.read_excel(file_path, sheet_name='spam')\n",
        "\n",
        "# Preprocess the data\n",
        "df = data[['v1', 'v2']].dropna()\n",
        "texts = df['v2'].values\n",
        "labels = df['v1'].values\n",
        "\n",
        "# Encode the labels (spam=1, ham=0)\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)"
      ],
      "metadata": {
        "id": "kTw17RyJI2FV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts_train, texts_test, labels_train, labels_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenize the text\n",
        "vocab_size = 10000\n",
        "max_length = 100\n",
        "trunc_type = 'post'\n",
        "padding_type = 'post'\n",
        "oov_tok = \"<OOV>\"\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(texts_train)\n",
        "word_index = tokenizer.word_index\n"
      ],
      "metadata": {
        "id": "bZlX58BpJcQn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sequences = tokenizer.texts_to_sequences(texts_train)\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "texts_test = [str(text) for text in texts_test]\n",
        "test_sequences = tokenizer.texts_to_sequences(texts_test)\n",
        "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n"
      ],
      "metadata": {
        "id": "DFpu1oqUJhuX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, 16, input_length=max_length),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(24, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "CryegqLsKGRZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "history = model.fit(train_padded, labels_train, epochs=num_epochs, validation_data=(test_padded, labels_test), verbose=2)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(test_padded, labels_test, verbose=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSTEdfXOKWoU",
        "outputId": "f5906788-78ea-4182-ba3b-476287b0eb8e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "140/140 - 2s - loss: 0.4762 - accuracy: 0.8661 - val_loss: 0.3612 - val_accuracy: 0.8655 - 2s/epoch - 16ms/step\n",
            "Epoch 2/10\n",
            "140/140 - 1s - loss: 0.3438 - accuracy: 0.8661 - val_loss: 0.3320 - val_accuracy: 0.8655 - 877ms/epoch - 6ms/step\n",
            "Epoch 3/10\n",
            "140/140 - 1s - loss: 0.2991 - accuracy: 0.8661 - val_loss: 0.2738 - val_accuracy: 0.8655 - 670ms/epoch - 5ms/step\n",
            "Epoch 4/10\n",
            "140/140 - 1s - loss: 0.2028 - accuracy: 0.9031 - val_loss: 0.1676 - val_accuracy: 0.9480 - 660ms/epoch - 5ms/step\n",
            "Epoch 5/10\n",
            "140/140 - 1s - loss: 0.1115 - accuracy: 0.9699 - val_loss: 0.1083 - val_accuracy: 0.9695 - 657ms/epoch - 5ms/step\n",
            "Epoch 6/10\n",
            "140/140 - 1s - loss: 0.0661 - accuracy: 0.9821 - val_loss: 0.0832 - val_accuracy: 0.9740 - 645ms/epoch - 5ms/step\n",
            "Epoch 7/10\n",
            "140/140 - 1s - loss: 0.0465 - accuracy: 0.9872 - val_loss: 0.0738 - val_accuracy: 0.9767 - 652ms/epoch - 5ms/step\n",
            "Epoch 8/10\n",
            "140/140 - 1s - loss: 0.0356 - accuracy: 0.9895 - val_loss: 0.0665 - val_accuracy: 0.9794 - 667ms/epoch - 5ms/step\n",
            "Epoch 9/10\n",
            "140/140 - 1s - loss: 0.0286 - accuracy: 0.9910 - val_loss: 0.0636 - val_accuracy: 0.9812 - 662ms/epoch - 5ms/step\n",
            "Epoch 10/10\n",
            "140/140 - 1s - loss: 0.0240 - accuracy: 0.9930 - val_loss: 0.0616 - val_accuracy: 0.9821 - 635ms/epoch - 5ms/step\n",
            "35/35 - 0s - loss: 0.0616 - accuracy: 0.9821 - 72ms/epoch - 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Loss: {loss}\")\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijEnl4z6Kd3_",
        "outputId": "1f288864-1921-4ca7-9a02-249ceedcafc3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.06155131384730339\n",
            "Accuracy: 0.9820627570152283\n"
          ]
        }
      ]
    }
  ]
}